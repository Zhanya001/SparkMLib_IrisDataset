{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import (\n",
    "    DecisionTreeClassifier,\n",
    "    GBTClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Crear la sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"Iris Classification\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+-------+\n",
      "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|species|\n",
      "+-----------------+----------------+-----------------+----------------+-------+\n",
      "|              5.1|             3.5|              1.4|             0.2|      0|\n",
      "|              4.9|             3.0|              1.4|             0.2|      0|\n",
      "|              4.7|             3.2|              1.3|             0.2|      0|\n",
      "|              4.6|             3.1|              1.5|             0.2|      0|\n",
      "|              5.0|             3.6|              1.4|             0.2|      0|\n",
      "+-----------------+----------------+-----------------+----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset CSV\n",
    "data = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Mostrar las primeras filas del dataset para comprobar la estructura\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-----------------+----------------+-------+\n",
      "|sepal length (cm)|sepal width (cm)|petal length (cm)|petal width (cm)|species|\n",
      "+-----------------+----------------+-----------------+----------------+-------+\n",
      "|              5.1|             3.5|              1.4|             0.2|      0|\n",
      "|              4.9|             3.0|              1.4|             0.2|      0|\n",
      "|              4.7|             3.2|              1.3|             0.2|      0|\n",
      "|              4.6|             3.1|              1.5|             0.2|      0|\n",
      "|              5.0|             3.6|              1.4|             0.2|      0|\n",
      "+-----------------+----------------+-----------------+----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el dataset para incluir solo dos clases (0 y 1) para clasificación binaria\n",
    "binary_data = data.filter(data[\"species\"].isin(0, 1))\n",
    "\n",
    "# Mostrar las primeras filas del dataset filtrado\n",
    "binary_data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar en vector los datos numéricos usando VectorAssembler\n",
    "# Definir las columnas de características\n",
    "feature_columns = [\n",
    "    \"sepal length (cm)\",\n",
    "    \"sepal width (cm)\",\n",
    "    \"petal length (cm)\",\n",
    "    \"petal width (cm)\",\n",
    "]\n",
    "\n",
    "# Crear el VectorAssembler para las características\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Transformar las características y agregar la columna 'features' al DataFrame\n",
    "binary_data = assembler.transform(binary_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----------------+\n",
      "|species|label|         features|\n",
      "+-------+-----+-----------------+\n",
      "|      0|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "|      0|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|      0|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "|      0|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|      0|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "+-------+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transformar los datos correspondientes a la columna especies usando StringIndexer\n",
    "# Crear el StringIndexer para la columna 'species'\n",
    "indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")\n",
    "\n",
    "# Ajustar el indexador en el conjunto de datos filtrado\n",
    "binary_data = indexer.fit(binary_data).transform(binary_data)\n",
    "\n",
    "# Convertir la columna 'label' a tipo Double (necesario para GBTClassifier)\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "binary_data = binary_data.withColumn(\"label\", binary_data[\"label\"].cast(DoubleType()))\n",
    "\n",
    "# Mostrar las primeras filas para verificar las nuevas columnas\n",
    "binary_data.select(\"species\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|   38|\n",
      "|  1.0|   45|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "train_data, test_data = binary_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Verificar la distribución de clases en el conjunto de entrenamiento\n",
    "train_data.groupBy(\"label\").count().show()\n",
    "\n",
    "# %%\n",
    "# Evaluador de clasificación\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo Decision Tree: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calcular la predicción y precisión usando Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "# Realizar predicciones sobre los datos de prueba\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "# Evaluar la precisión del modelo\n",
    "dt_accuracy = evaluator.evaluate(dt_predictions)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Precisión del modelo Decision Tree: {dt_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo Gradient-Boosted Tree: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calcular la predicción y precisión usando Gradient-Boosted Tree Classifier\n",
    "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
    "\n",
    "# Entrenar el modelo\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# Realizar predicciones sobre los datos de prueba\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Evaluar la precisión del modelo\n",
    "gbt_accuracy = evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Precisión del modelo Gradient-Boosted Tree: {gbt_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo Random Forest: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calcular la predicción y precisión usando Random Forest Classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=100)\n",
    "\n",
    "# Entrenar el modelo\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Realizar predicciones sobre los datos de prueba\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Evaluar la precisión del modelo\n",
    "rf_accuracy = evaluator.evaluate(rf_predictions)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(f\"Precisión del modelo Random Forest: {rf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizar la sesión de Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
